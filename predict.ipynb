{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0b1ee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import f_regression\n",
    "from scipy import stats\n",
    "\n",
    "data = pd.read_csv('Final Features.csv')\n",
    "data = data.rename(columns={'Life Expectancy at Birth, both sexes (years)': 'target'})\n",
    "\n",
    "# Preprocessing\n",
    "for feature in data.columns:\n",
    "    if data[feature].dtype != 'object':\n",
    "        if abs(data[feature].skew()) > 1:\n",
    "            # Use IQR to manage non-normal distribution\n",
    "            Q1 = data[feature].quantile(0.25)\n",
    "            Q3 = data[feature].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_limit = Q1 - 1.5 * IQR\n",
    "            upper_limit = Q3 + 1.5 * IQR\n",
    "            data[feature] = np.where((data[feature] < lower_limit) | (data[feature] > upper_limit), np.nan, data[feature])\n",
    "        else:\n",
    "            # Use standard deviation to manage normal distribution\n",
    "            mean = data[feature].mean()\n",
    "            std = data[feature].std()\n",
    "            lower_limit = mean - 3 * std\n",
    "            upper_limit = mean + 3 * std\n",
    "            data[feature] = np.where((data[feature] < lower_limit) | (data[feature] > upper_limit), np.nan, data[feature])\n",
    "    \n",
    "# Handle missing data using KNN imputation\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# Remove features with high correlation\n",
    "corr_matrix = data.corr()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper_tri.columns if any(abs(upper_tri[column]) > 0.90)]\n",
    "data.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Split data into input and output variables\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "clf = LinearRegression()\n",
    "pipeline = make_pipeline(RobustScaler(), clf)\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# K-fold cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "r2_scores = []\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'normalize': [True, False],\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "# Find the best hyperparameters using GridSearchCV\n",
    "grid_search = GridSearchCV(LinearRegression(), param_grid, cv=kf, scoring='r2')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best hyperparameters and R-squared score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best R-squared score: \", grid_search.best_score_)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = LinearRegression(normalize=grid_search.best_params_['normalize'], fit_intercept=grid_search.best_params_['fit_intercept'])\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_pred = best_model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared on test set: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa94c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new data and preprocess it\n",
    "new_data = pd.read_csv('2.csv')\n",
    "ls = X_train.columns.values.tolist()\n",
    "new_data = new_data.filter(ls)\n",
    "for feature in new_data.columns:\n",
    "    if new_data[feature].dtype != 'object':\n",
    "        if abs(new_data[feature].skew()) > 1:\n",
    "            Q1 = new_data[feature].quantile(0.25)\n",
    "            Q3 = new_data[feature].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_limit = Q1 - 1.5 * IQR\n",
    "            upper_limit = Q3 + 1.5 * IQR\n",
    "            new_data[feature] = np.where((new_data[feature] < lower_limit) | (new_data[feature] > upper_limit), np.nan, new_data[feature])\n",
    "        else:\n",
    "            mean = new_data[feature].mean()\n",
    "            std = new_data[feature].std()\n",
    "            lower_limit = mean - 3 * std\n",
    "            upper_limit = mean + 3 * std\n",
    "            new_data[feature] = np.where((new_data[feature] < lower_limit) | (new_data[feature] > upper_limit), np.nan, new_data[feature])\n",
    "    else:\n",
    "        new_data[feature] = pd.factorize(new_data[feature])[0]\n",
    "\n",
    "# Handle missing data using KNN imputation\n",
    "new_data = pd.DataFrame(imputer.transform(new_data), columns=new_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70930df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the new data\n",
    "y_new_pred = best_model.predict(new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
